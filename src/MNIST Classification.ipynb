{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We will be using the MNIST dataset, which is a set of 70,000 small\n",
    "images of digits handwritten by high school students and employees of the US Cen‐\n",
    "sus Bureau. Each image is labeled with the digit it represents. This set has been stud‐\n",
    "ied so much that it is often called the “Hello World” of Machine Learning: whenever\n",
    "people come up with a new classification algorithm, they are curious to see how it\n",
    "will perform on MNIST. Whenever someone learns Machine Learning, sooner or\n",
    "later they tackle MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (70000, 784)\n",
      "Target: (70000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(\"Features:\", X.shape)\n",
    "print(\"Target:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "'''The above one looks like 9, lets verify'''\n",
    "print(y[36000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The MNIST dataset is actually already split into a training set (the first 60,000\n",
    "images) and a test set (the last 10,000 images)\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let’s also shuffle the training set. \n",
    "This will guarantee that all cross-validation folds will be similar'''\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b9799f936892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''Training a Binary Classifier for one digit only 5'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "'''Training a Binary Classifier for one digit only 5'''\n",
    "y_train_5 = (int(y_train) == 5)\n",
    "y_test_5 = (int(y_test) == 5)\n",
    "y_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0301d354835c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''Start with SGDClassifier'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msgd_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msgd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    711\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0;32m--> 554\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    516\u001b[0m             raise ValueError(\n\u001b[1;32m    517\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \" got %d class\" % n_classes)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "'''Start with SGDClassifier'''\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
